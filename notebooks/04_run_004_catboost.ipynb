{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 004 - CatBoostRegressor & Log Target\n",
                "\n",
                "## Objectif\n",
                "Utiliser **CatBoostRegressor** pour exploiter nativement les variables catégorielles (sans OneHotEncoder qui peut perdre de l'information ou créer trop de dimensions).\n",
                "Toujours avec :\n",
                "- Transformation Log1p sur la cible.\n",
                "- Validation croisée (MAE/MAPE).\n",
                "- Early Stopping pour éviter l'overfitting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from catboost import CatBoostRegressor, Pool\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
                "import os\n",
                "\n",
                "sns.set_style(\"whitegrid\")\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Chargement et Préparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "TRAIN_PATH = \"../Data/train.csv\"\n",
                "TEST_PATH = \"../Data/test.csv\"\n",
                "\n",
                "train_df = pd.read_csv(TRAIN_PATH)\n",
                "test_df = pd.read_csv(TEST_PATH)\n",
                "\n",
                "X = train_df.drop(columns=[\"SalePrice\"])\n",
                "y = train_df[\"SalePrice\"]\n",
                "X_test = test_df\n",
                "\n",
                "# Identification des colonnes catégorielles\n",
                "cat_features = list(X.select_dtypes(include=[\"object\"]).columns)\n",
                "print(f\"Categorical features: {len(cat_features)}\")\n",
                "\n",
                "# Préparation pour CatBoost : Conversion en string et remplissage des NaNs catégoriels\n",
                "for col in cat_features:\n",
                "    X[col] = X[col].astype(str).fillna(\"Missing\")\n",
                "    X_test[col] = X_test[col].astype(str).fillna(\"Missing\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Transformation Log de la cible\n",
                "y_log = np.log1p(y)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Tuning Léger (Manuel avec CV)\n",
                "\n",
                "Nous allons tester quelques configurations aléatoires pour trouver de bons hyperparamètres, tout en utilisant l'early stopping sur chaque fold."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "\n",
                "def train_evaluate_cv(params, X, y_log, cat_features):\n",
                "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "    mae_scores = []\n",
                "    mape_scores = []\n",
                "    \n",
                "    # Note: On passe les DataFrame directement à CatBoost\n",
                "    \n",
                "    for train_index, val_index in kf.split(X):\n",
                "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
                "        y_train_log, y_val_log = y_log.iloc[train_index], y_log.iloc[val_index]\n",
                "        \n",
                "        train_pool = Pool(X_train, y_train_log, cat_features=cat_features)\n",
                "        val_pool = Pool(X_val, y_val_log, cat_features=cat_features)\n",
                "        \n",
                "        model = CatBoostRegressor(**params, silent=True, allow_writing_files=False)\n",
                "        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=200, verbose=False)\n",
                "        \n",
                "        # Prédiction (log scale) -> Inverse (real scale)\n",
                "        preds_log = model.predict(X_val)\n",
                "        preds = np.expm1(preds_log)\n",
                "        y_val_true = np.expm1(y_val_log)\n",
                "        \n",
                "        mae_scores.append(mean_absolute_error(y_val_true, preds))\n",
                "        mape_scores.append(mean_absolute_percentage_error(y_val_true, preds))\n",
                "        \n",
                "    return np.mean(mae_scores), np.mean(mape_scores)\n",
                "\n",
                "# Grille de recherche\n",
                "param_grid = {\n",
                "    'depth': [4, 6, 8],\n",
                "    'learning_rate': [0.01, 0.03, 0.05],\n",
                "    'l2_leaf_reg': [1, 3, 5, 7],\n",
                "    'random_strength': [1, 2],\n",
                "    'iterations': [2000] # Suffisant avec early stopping\n",
                "}\n",
                "\n",
                "best_mae = float('inf')\n",
                "best_params = {}\n",
                "\n",
                "print(\"Début du tuning (10 essais)...\")\n",
                "random.seed(42)\n",
                "\n",
                "for i in range(10):\n",
                "    # Sampling aléatoire\n",
                "    params = {\n",
                "        'loss_function': 'MAE',\n",
                "        'random_seed': 42,\n",
                "        'iterations': 2000,\n",
                "        'depth': random.choice(param_grid['depth']),\n",
                "        'learning_rate': random.choice(param_grid['learning_rate']),\n",
                "        'l2_leaf_reg': random.choice(param_grid['l2_leaf_reg']),\n",
                "        'random_strength': random.choice(param_grid['random_strength']),\n",
                "    }\n",
                "    \n",
                "    mae, mape = train_evaluate_cv(params, X, y_log, cat_features)\n",
                "    print(f\"Iter {i+1}: MAE={mae:.2f}, MAPE={mape*100:.2f}%, Params={params}\")\n",
                "    \n",
                "    if mae < best_mae:\n",
                "        best_mae = mae\n",
                "        best_params = params\n",
                "        \n",
                "print(f\"\\nBest MAE: {best_mae:.2f}\")\n",
                "print(f\"Best Params: {best_params}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Entraînement Final et Soumission"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# On entraîne sur TOUT le train set\n",
                "# Note : sans eval_set, pas d'early stopping classique. \n",
                "# On utilise les paramètres optimaux et on laisse tourner (ou on fixe iterations a une moyenne observée).\n",
                "full_pool = Pool(X, y_log, cat_features=cat_features)\n",
                "test_pool = Pool(X_test, cat_features=cat_features)\n",
                "\n",
                "final_model = CatBoostRegressor(**best_params, silent=True, allow_writing_files=False)\n",
                "final_model.fit(full_pool)\n",
                "\n",
                "preds_log = final_model.predict(test_pool)\n",
                "preds = np.expm1(preds_log)\n",
                "\n",
                "submission = pd.DataFrame({\n",
                "    \"Id\": X_test[\"Id\"],\n",
                "    \"SalePrice\": preds\n",
                "})\n",
                "\n",
                "submission.head()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}